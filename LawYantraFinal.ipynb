{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Nfy-pH-zW8Y"
      },
      "outputs": [],
      "source": [
        "# Installing dependancies\n",
        "!pip install chromadb openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing dependancies\n",
        "import json\n",
        "import openai\n",
        "import chromadb\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "fTdtHmoKz3tB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up the api key\n",
        "openai.api_key = \"\""
      ],
      "metadata": {
        "id": "dAcm-wMCz3qg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the reasoning class\n",
        "class LLMReasoning:\n",
        "  def __init__(self):\n",
        "    # Defining the system\n",
        "    self.SYSTEM_DEFINITION = \"\"\"DETECT TYPE OF LAW ASSOCIATED:\n",
        "                              Given the input, identify the types of laws that can come under that situation,\n",
        "                              and other entitities that provided in the examples, be precise and\n",
        "                              don't over complicate the situation and give too many offences.\n",
        "                              USE LOGICAL REASONING TO THE BEST OF YOUR ABILITY AS IF YOU HAVE TO Decide the CASE ACTUALLY.\n",
        "                              ---------------------------------------------------------------------\n",
        "\n",
        "                              STRICTLY CHOOSE FROM THIS ONLY IF NOT PRESENT IN THIS DON'T INCLUDE:\n",
        "                              {AVAILABLE_LABELS}\n",
        "\n",
        "                              STRICTLY ANSWER IN THE FORMAT GIVEN, IF NOT POSSIBLE STRICTLY RETURN [] ALWAYS.\n",
        "                              Here are examples:\n",
        "\n",
        "                              {\n",
        "                                  \"Category\": [\"family law\", \"criminal law\"],\n",
        "                                  \"Extras\": {\n",
        "                                      \"language\": \"The language appears to be informal or possibly a non-native form of English.\",\n",
        "                                      \"location\": \"\", <strictly one of the indian states if available else \"\">\n",
        "                                      \"charge\": \"\", <strictly an integer if filling the value other than empty string, if not available fill with 200>\n",
        "                                      \"time\": \"\", <strictly in number of days form>\n",
        "                                      \"practicesat\": \"\",\n",
        "                                      \"clientdemographics\": \"\",\n",
        "                                      \"Typesoflaws\": [\"family law\", \"criminal law\"],\n",
        "                                      \"ClientFeedback\": \"\"\n",
        "                                  }\n",
        "                              }\n",
        "\n",
        "                              ________________________________________________________________\n",
        "                              Sentence: 'Two brothers were tenant of a landlord in a commercial property.One brother had one son and a\n",
        "                              daughter (both minor) when he got divorced with his wife.The children's went into mother's custody at the\n",
        "                              time of divorce and after some years the husband (co tenant) also died. Now can the children of the\n",
        "                              deceased brother(co tenant) claim the right'\n",
        "                              Sol: {\"Category\": [\\n    \"family law\",\\n    \"criminal law\"\\n  ],\\n  \"Extras\": {\\n    \"language\": \"\",\\n    \"location\": \"\",\\n    \"charge\": \"\",\\n    \"practicesat\": \"\",\\n    \"clientdemographics\": \"Individuals\",\\n    \"Typesoflaws\": [\\n      \"family law\",\\n      \"criminal law\"\\n    ],\\n    \"ClientFeedback\": 3\\n  }\\n}\n",
        "                              ________________________________________________________________\n",
        "                              Sentence: 'hi dear sir @ madam i am work enterprises shop casher my owner my big bother my owner all\n",
        "                              cosmer money take and leave in city all cosmer tarcher and attack me and my family what i do sir'\n",
        "                              Sol: {\"Category\": [\\n    \"family law\",\\n    \"criminal law\"\\n  ],\\n  \"Extras\": {\\n    \"language\": \"The language appears to be informal or possibly a non-native form of English.\",\\n    \"location\": \"\",\\n    \"charge\": \"\",\\n    \"time\": null,\\n    \"practicesat\": \"\",\\n    \"clientdemographics\": \"\",\\n    \"Typesoflaws\": [\\n      \"family law\",\\n      \"criminal law\"\\n    ],\\n    \"ClientFeedback\": \"\"\\n  }\\n}\n",
        "                              ________________________________________________________________\n",
        "\n",
        "                              Sentence: {task}\n",
        "                              Operations:\n",
        "\n",
        "                              <STRICTLY COMPLETE THE DICTIONARY LOGICALLY AND AS PER THE Sol provided>\n",
        "                              \"\"\"\n",
        "\n",
        "  # To get apply reasoning on the input query for VectorDB embeddings\n",
        "  def llmReasoning(self, text):\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": self.SYSTEM_DEFINITION},\n",
        "            {\"role\": \"user\", \"content\": text}\n",
        "        ],\n",
        "        max_tokens=100\n",
        "    )\n",
        "    output_text = response.choices[0].message.content\n",
        "\n",
        "    return output_text\n",
        "\n",
        "  # Run the model\n",
        "  def run(self, text):\n",
        "    outputText = self.llmReasoning(text)\n",
        "    InputForVectorDB = json.loads(outputText)\n",
        "\n",
        "    com = InputForVectorDB['Extras']\n",
        "    genQuery = f\"\"\"The language = {com['language']},\n",
        "                location = {com['location']}, charge = {com['charge']},\n",
        "                time = {com['time']}, practicesat = {com['practicesat']},\n",
        "                clientdemographics = {com['clientdemographics']},\n",
        "                Typesoflaws = {com['Typesoflaws']},\n",
        "                ClientFeedback = {com['ClientFeedback']}\"\"\"\n",
        "\n",
        "    return genQuery"
      ],
      "metadata": {
        "id": "96ZTTFN3z3of"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vector database pipeline to update the embeddings in the db\n",
        "class VectorDBPipeline:\n",
        "  def __init__(self, path='/content/updated_merged_data.csv'):\n",
        "    self.chroma_client = chromadb.Client()\n",
        "    self.collection = self.chroma_client.create_collection(name=\"LawyerCollection\")\n",
        "    self.df = pd.read_csv(path)\n",
        "    self.df = self.df.drop(self.df.index[0])\n",
        "    # self.df = self.df.drop(columns=['Unnamed: 0'])\n",
        "\n",
        "  # Adding the vectors\n",
        "  def add_vectortoDB(self):\n",
        "      for i in range(len(self.df)):\n",
        "        update = {\n",
        "          \"language\": self.df.iloc[i]['language'],\n",
        "          \"location\": self.df.iloc[i]['location'],\n",
        "          \"charge\": self.df.iloc[i]['charge'],\n",
        "          \"time\": self.df.iloc[i]['time'],\n",
        "          \"practicesat\": self.df.iloc[i]['practicesat'],\n",
        "          \"clientdemographics\": self.df.iloc[i]['clientdemographics'],\n",
        "          \"Typesoflaws\": self.df.iloc[i]['Typesoflaws'],\n",
        "          \"ClientFeedbackof\": self.df.iloc[i]['ClientFeedbackof']\n",
        "        }\n",
        "\n",
        "        # Convert the dictionary to a JSON-formatted string\n",
        "        update_str = json.dumps(update)\n",
        "\n",
        "        self.collection.add(\n",
        "          documents=[update_str],\n",
        "          metadatas=[{\"source\": \"LawData\"}],\n",
        "          ids=[f\"{i+1}\"]\n",
        "        )\n",
        "\n",
        "  # Get query from the DB\n",
        "  def run_query(self, query):\n",
        "    results = self.collection.query(query_texts=[query],\n",
        "                               n_results=5)\n",
        "    res = results['documents'][0]\n",
        "    access = []\n",
        "    for elem in res:\n",
        "      access.append(elem)\n",
        "\n",
        "    return access"
      ],
      "metadata": {
        "id": "tCFfLvM8z3l3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up the vector db pipeline\n",
        "vector_db_pipeline = VectorDBPipeline('/content/cleaned_data.csv')\n",
        "vector_db_pipeline.add_vectortoDB()"
      ],
      "metadata": {
        "id": "fqT6WDU9z3jX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the system\n",
        "# query = \"im a marathi person i got laid off by a company i need a senior lawyer who is based in my state to fight my case, he shoukd also have a good custmer feedback, i need the case solved as soon as possible\"\n",
        "query = \"I'm a woman facing dowry harassment in Delhi. I need a lawyer who can help me file a dowry harassment case against my in-laws.\"\n",
        "reasoningModel = LLMReasoning()\n",
        "InputForVectorDB = reasoningModel.run(query)\n",
        "result = vector_db_pipeline.run_query(InputForVectorDB)\n",
        "result"
      ],
      "metadata": {
        "id": "HOPXSAffz3g6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reasoningModel.llmReasoning(query)"
      ],
      "metadata": {
        "id": "nTLTu8zu2vza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(result)"
      ],
      "metadata": {
        "id": "t5bHVCRk2vxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for res in result:\n",
        "  print(json.loads(res))"
      ],
      "metadata": {
        "id": "0AbLvi0_2vuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chromadb langchain openai tiktoken"
      ],
      "metadata": {
        "id": "6r3L1wff2vsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next = pd.read_csv('/content/master.csv')\n",
        "next = next.drop(next.columns[0], axis=1)\n",
        "next.head()"
      ],
      "metadata": {
        "id": "cm67Zrud2vp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.document_loaders.csv_loader import CSVLoader\n",
        "\n",
        "loader = CSVLoader(file_path=\"/content/master.csv\")\n",
        "data= loader.load()\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "texts = text_splitter.split_documents(data)\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\", openai_api_key=\"\")\n",
        "llm = OpenAI(openai_api_key=\"\")\n",
        "docsearch = Chroma.from_documents(texts, embeddings)\n",
        "\n",
        "qa = RetrievalQA.from_chain_type(llm=llm, chain_type='stuff', retriever=docsearch.as_retriever())"
      ],
      "metadata": {
        "id": "XJMdXgeo2vnc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categories = json.loads(reasoningModel.llmReasoning(query))\n",
        "categories = categories['Extras']\n",
        "categories = json.dumps(categories)\n",
        "categories"
      ],
      "metadata": {
        "id": "YbRBbQmN2vlI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = docsearch.similarity_search(\n",
        "    categories, distance_metric=\"cos\", k=10\n",
        ")\n",
        "results"
      ],
      "metadata": {
        "id": "2FbiAPUB2vig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_5_page_content = [result.page_content for result in results]\n",
        "\n",
        "# Split the text into separate entries\n",
        "entries = [content.split('\\n') for content in top_5_page_content]\n",
        "\n",
        "# Create a list of tuples to represent the data\n",
        "data = [(\"Lawyer Names\", entry[-1].split(\": \")[1], \"index\", entry[0].split(\": \")[1]) for entry in entries]\n",
        "\n",
        "# Convert the list of tuples into a set to remove duplicates\n",
        "unique_data = set(data)\n",
        "\n",
        "# If you want to convert it back to a list of dictionaries, you can do so\n",
        "unique_data_list = [{\"Lawyer Names\": item[1], \"Index\": item[3]} for item in unique_data]\n",
        "\n",
        "df = pd.DataFrame(unique_data_list)\n",
        "\n",
        "df.head(5)"
      ],
      "metadata": {
        "id": "SIU6TPrS2vgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize an empty list to store the corresponding rows from \"next\"\n",
        "corresponding_rows = []\n",
        "\n",
        "# Iterate over the \"Index\" values in the \"df\" DataFrame\n",
        "for index_value in df['Index']:\n",
        "    # Find the row in the \"next\" DataFrame where the 'index' matches the current index_value\n",
        "    print(index_value)\n",
        "    matching_row = next[next['index'] == index_value]\n",
        "\n",
        "    # Append the matching row to the list\n",
        "    corresponding_rows.append(matching_row)\n",
        "\n",
        "# Convert the list of rows to a new DataFrame\n",
        "corresponding_df = pd.concat(corresponding_rows, ignore_index=True)\n",
        "\n",
        "# Display the resulting DataFrame\n",
        "print(corresponding_df)\n"
      ],
      "metadata": {
        "id": "PGubu7a-2vdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GEN_DISPLAY_QUERY = \"\"\"\"\"\"\n",
        "\n",
        "# Iterate over the first 5 rows in the 'df' DataFrame\n",
        "for i in range(5):\n",
        "    try:\n",
        "      name = df.iloc[i]['Lawyer Names']\n",
        "      index = df.iloc[i]['Index']\n",
        "\n",
        "      # Find the row in 'next' DataFrame that matches the 'index'\n",
        "      row = next[next['index'] == int(index)].iloc[0].to_dict()\n",
        "\n",
        "      # Print the formatted output\n",
        "      out = f\"\"\"\n",
        "      Name: {name},\n",
        "      Languages: {row['language']},\n",
        "      Location: {row['location']},\n",
        "      Average Charge: {row['charge']},\n",
        "      Average Time: {row['time']},\n",
        "      Practices at: {row['practicesat']},\n",
        "      Client Demographics: {row['clientdemographics']},\n",
        "      Laws associated: {row['Typesoflaws']},\n",
        "      Client Feedback Rating: {row['ClientFeedbackof']}\n",
        "      \"\"\"\n",
        "      # print(out)\n",
        "      GEN_DISPLAY_QUERY += out\n",
        "    except:\n",
        "      pass\n"
      ],
      "metadata": {
        "id": "-4AiCWBf2urR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(GEN_DISPLAY_QUERY)"
      ],
      "metadata": {
        "id": "W5tqyqCq2_pu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = next[next[\"index\"] == 1285]\n",
        "a.to_dict()"
      ],
      "metadata": {
        "id": "ixrgHxFI2_my"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "id": "O8KN21oP2_kV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader2 = CSVLoader(file_path=\"/content/LawYantra Dataset - lawyer_summaries.csv\")\n",
        "data2= loader2.load()\n",
        "text_splitter2 = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "texts2 = text_splitter.split_documents(data2)\n",
        "docsearch2 = Chroma.from_documents(texts2, embeddings)\n",
        "\n",
        "qa2 = RetrievalQA.from_chain_type(llm=llm, chain_type='stuff', retriever=docsearch2.as_retriever())"
      ],
      "metadata": {
        "id": "xklvVEGi2_iB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEFINITION = \"\"\"\n",
        "You are an Explainable AI bot that gets details of lawyers\n",
        "which are {text}, and a query: {query}, result\n",
        "in a way such that it explains why the lawyers are a perfect match for the query.\n",
        "STRICTLY REFER THE DATA PROVIDED TO YOU ONLY AND ANSWER THROUGH IT\n",
        "\n",
        "\"\"\"\n",
        "def recommendation(text, query):\n",
        "    found = f\"Lawyers: {text}, Query: {query}\"\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": DEFINITION},\n",
        "            {\"role\": \"user\", \"content\": DEFINITION.format(text=text, query=query)}\n",
        "        ],\n",
        "        max_tokens=100\n",
        "    )\n",
        "    output_text = response.choices[0].message.content\n",
        "\n",
        "    return output_text"
      ],
      "metadata": {
        "id": "t2HdceMS2_eX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def echo(query, history):\n",
        "    # query = \"I'm a woman facing dowry harassment in Delhi. I need a lawyer who can help me file a dowry harassment case against my in-laws.\"\n",
        "    if \"/start\" in query:\n",
        "      # reasoningModel = LLMReasoning()\n",
        "      # InputForVectorDB = reasoningModel.run(query)\n",
        "      # result = vector_db_pipeline.run_query(InputForVectorDB)\n",
        "\n",
        "      categories = json.loads(reasoningModel.llmReasoning(query))\n",
        "      # ai_recommendation = qa.run(\", \".join(categories['Category']))\n",
        "\n",
        "      categories = categories['Extras']\n",
        "      categories = json.dumps(categories)\n",
        "\n",
        "      results = docsearch2.similarity_search(\n",
        "          categories, distance_metric=\"cos\", k=5\n",
        "      )\n",
        "\n",
        "      top_5_page_content = [result.page_content for result in results]\n",
        "\n",
        "      # Split the text into separate entries\n",
        "      entries = [content.split('\\n') for content in top_5_page_content]\n",
        "\n",
        "      # Create a list of tuples to represent the data\n",
        "      data = [(\"Lawyer Names\", entry[-1].split(\": \")[1], \"index\", entry[0].split(\": \")[1]) for entry in entries]\n",
        "\n",
        "      # Convert the list of tuples into a set to remove duplicates\n",
        "      unique_data = set(data)\n",
        "\n",
        "      # If you want to convert it back to a list of dictionaries, you can do so\n",
        "      unique_data_list = [{\"Lawyer Names\": item[1], \"Index\": item[3]} for item in unique_data]\n",
        "\n",
        "      df = pd.DataFrame(unique_data_list)\n",
        "\n",
        "      GEN_DISPLAY_QUERY = \"\"\"\"\"\"\n",
        "      ai_recommendation = recommendation(GEN_DISPLAY_QUERY, query)\n",
        "\n",
        "      # Iterate over the first 5 rows in the 'df' DataFrame\n",
        "      for i in range(5):\n",
        "          try:\n",
        "            name = df.iloc[i]['Lawyer Names']\n",
        "            index = df.iloc[i]['Index']\n",
        "\n",
        "            # Find the row in 'next' DataFrame that matches the 'index'\n",
        "            row = next[next['index'] == int(index)].iloc[0].to_dict()\n",
        "\n",
        "            # Print the formatted output\n",
        "            out = f\"\"\"\n",
        "            Name: {name},\n",
        "            Languages: {row['language']},\n",
        "            Location: {row['location']},\n",
        "            Average Charge: {row['charge']},\n",
        "            Average Time: {row['time']},\n",
        "            Practices at: {row['practicesat']},\n",
        "            Client Demographics: {row['clientdemographics']},\n",
        "            Laws associated: {row['Typesoflaws']},\n",
        "            Client Feedback Rating: {row['ClientFeedbackof']}\n",
        "            \"\"\"\n",
        "            # print(out)\n",
        "            GEN_DISPLAY_QUERY += out\n",
        "          except:\n",
        "            pass\n",
        "\n",
        "      fin = GEN_DISPLAY_QUERY + ai_recommendation\n",
        "\n",
        "      return fin\n",
        "    else:\n",
        "      SYSTEM_DEF = \"\"\"\n",
        "      You are a virtual assistant named LawYantra, that responds only to the Law related queries.\n",
        "      based in India. Give accurate on the point suggestions for normal people.\n",
        "      You are a law assistant chatbot, if you know the answer to the query still\n",
        "      politely decline the user from answering any other query except law related.\n",
        "      \"\"\"\n",
        "      response = openai.ChatCompletion.create(\n",
        "          model=\"gpt-3.5-turbo\",\n",
        "          messages=[\n",
        "              {\"role\": \"system\", \"content\": SYSTEM_DEF},\n",
        "              {\"role\": \"user\", \"content\": query}\n",
        "          ],\n",
        "          max_tokens=100\n",
        "      )\n",
        "      output_text = response.choices[0].message.content\n",
        "      return output_text\n",
        "\n",
        "\n",
        "demo = gr.ChatInterface(fn=echo, examples=[\"hello\", \"hola\", \"merhaba\"], title=\"Law Yantra\")\n",
        "demo.launch(debug=True)"
      ],
      "metadata": {
        "id": "mPc4ImXI3Exb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categories = json.loads(reasoningModel.llmReasoning(query))\n",
        "# ai_recommendation = qa.run(\", \".join(categories['Category']))\n",
        "\n",
        "categories = categories['Extras']\n",
        "categories = json.dumps(categories)\n",
        "\n",
        "results = docsearch2.similarity_search(\n",
        "    categories, distance_metric=\"cos\", k=5\n",
        ")\n",
        "\n",
        "top_5_page_content = [result.page_content for result in results]\n",
        "\n",
        "# Split the text into separate entries\n",
        "entries = [content.split('\\n') for content in top_5_page_content]\n",
        "\n",
        "# Create a list of tuples to represent the data\n",
        "data = [(\"Lawyer Names\", entry[-1].split(\": \")[1], \"index\", entry[0].split(\": \")[1]) for entry in entries]\n",
        "\n",
        "# Convert the list of tuples into a set to remove duplicates\n",
        "unique_data = set(data)\n",
        "\n",
        "# If you want to convert it back to a list of dictionaries, you can do so\n",
        "unique_data_list = [{\"Lawyer Names\": item[1], \"Index\": item[3]} for item in unique_data]\n",
        "\n",
        "df = pd.DataFrame(unique_data_list)\n",
        "\n",
        "GEN_DISPLAY_QUERY = \"\"\"\"\"\"\n",
        "ai_recommendation = recommendation(GEN_DISPLAY_QUERY, query)\n",
        "\n",
        "# Iterate over the first 5 rows in the 'df' DataFrame\n",
        "for i in range(5):\n",
        "    try:\n",
        "      name = df.iloc[i]['Lawyer Names']\n",
        "      index = df.iloc[i]['Index']\n",
        "\n",
        "      # Find the row in 'next' DataFrame that matches the 'index'\n",
        "      row = next[next['index'] == int(index)].iloc[0].to_dict()\n",
        "\n",
        "      # Print the formatted output\n",
        "      out = f\"\"\"\n",
        "      Name: {name},\n",
        "      Languages: {row['language']},\n",
        "      Location: {row['location']},\n",
        "      Average Charge: {row['charge']},\n",
        "      Average Time: {row['time']},\n",
        "      Practices at: {row['practicesat']},\n",
        "      Client Demographics: {row['clientdemographics']},\n",
        "      Laws associated: {row['Typesoflaws']},\n",
        "      Client Feedback Rating: {row['ClientFeedbackof']}\n",
        "      \"\"\"\n",
        "      # print(out)\n",
        "      GEN_DISPLAY_QUERY += out\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "fin = GEN_DISPLAY_QUERY + ai_recommendation\n",
        "\n",
        "print(fin)"
      ],
      "metadata": {
        "id": "0e_sYJNK3Eu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oL1p_qfn3EsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OwqW8neO3Ep5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}